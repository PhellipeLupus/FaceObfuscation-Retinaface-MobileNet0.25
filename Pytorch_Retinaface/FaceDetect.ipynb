{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248f7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Office\\anaconda3\\envs\\timesformer\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from retinaface import RetinaFace\n",
    "from cv2 import rectangle\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd8b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "import time\n",
    "\n",
    "\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee0a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_face(face, diagonal, frame_width, frame_height):\n",
    "    links_x, links_y, rechts_x, rechts_y = face\n",
    "    #  Diagonaal krijgen voor gauss blur, en box iets groter maken          \n",
    "    links_x, links_y, rechts_x, rechts_y = links_x -(diagonal/10), links_y-(diagonal/10), rechts_x+(diagonal/10), rechts_y+(diagonal/10)\n",
    "    if links_x<0:\n",
    "        links_x = 0\n",
    "    if links_y<0:\n",
    "        links_y = 0\n",
    "    if rechts_x>=frame_width:\n",
    "        rechts_x=frame_width-1\n",
    "    if rechts_y>=frame_height:\n",
    "        rechts_y=frame_height-1\n",
    "    return int(links_x), int(links_y), int(rechts_x), int(rechts_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f4db2",
   "metadata": {},
   "source": [
    "### Loading the RetinaFace MobileNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4386ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "net = RetinaFace(cfg=cfg_mnet, phase = 'test')\n",
    "net = load_model(net, './weights/mobilenet0.25_Final.pth', True)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cpu\" if True else \"cuda\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a86c4",
   "metadata": {},
   "source": [
    "### Video tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf2d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(Video):\n",
    "    while(Video.isOpened()):\n",
    "        ret, frame = Video.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('Frame',frame)\n",
    "            key = cv2.waitKey(40)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # drop the video\n",
    "    Video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "def video_info(Video):\n",
    "    if (Video.isOpened() == False):\n",
    "        print(\"Error opening the video file\")\n",
    "    else:\n",
    "        fps = Video.get(5)\n",
    "        print('Frames per second : ', fps,'FPS')\n",
    "        frame_count = Video.get(7)\n",
    "        print('Frame count : ', frame_count)\n",
    "#     return Video.get(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565e278",
   "metadata": {},
   "source": [
    "### Face Detection Function MobileNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8243f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceDetect(frame):\n",
    "    img = np.float32(frame)\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    loc, conf, landms = net(img) \n",
    "    priorbox = PriorBox(cfg_mnet, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg_mnet['variance'])\n",
    "    boxes = boxes * scale \n",
    "    boxes = boxes.cpu().numpy()\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg_mnet['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 \n",
    "    landms = landms.cpu().numpy()\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > 0.02)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    order = scores.argsort()[::-1]\n",
    "    boxes = boxes[order]\n",
    "    landms = landms[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, 0.4)\n",
    "\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    # dets = dets[:args.keep_top_k, :]\n",
    "    # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    faces = []\n",
    "    for face in dets:\n",
    "        if face[4] > 0.5:\n",
    "            faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec45bc3",
   "metadata": {},
   "source": [
    "# Final Converter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726afdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_gauss_and_overlay(location, destination1, partition):\n",
    "    video = cv2.VideoCapture(location)\n",
    "    succes, frame = video.read() # get the next frame\n",
    "    frame_number = 0\n",
    "    width = video.get(3)\n",
    "    height = video.get(4)\n",
    "    fps = video.get(7)\n",
    "    mask = np.zeros_like(frame)\n",
    "    out = cv2.VideoWriter(destination1,cv2.VideoWriter_fourcc('M','J','P','G'), int(fps), (int(width),int(height)))\n",
    "    while succes: \n",
    "        if frame_number % partition == 0:\n",
    "            succes, frame = video.read()\n",
    "            if succes:\n",
    "                #  detect the faces\n",
    "                faces = FaceDetect(frame)\n",
    "                if len(faces)>0:\n",
    "                    overlay_frame = np.copy(frame)\n",
    "                    mask.fill(255)\n",
    "                    diagonal = 0\n",
    "                    for i in range(len(faces)):\n",
    "                        facial_area = faces[i][:4]\n",
    "                        local_diagonal = np.sqrt((facial_area[2]-facial_area[0])**2+(facial_area[3]-facial_area[1])**2)\n",
    "                        if local_diagonal > diagonal:\n",
    "                            diagonal = local_diagonal\n",
    "                        #  Hoeken van de box en box maken\n",
    "                        links_x, links_y, rechts_x, rechts_y = larger_face(facial_area, local_diagonal, width, height)\n",
    "                        cv2.rectangle(mask, (links_x, links_y), (rechts_x, rechts_y), (0, 0, 0), thickness=-1)\n",
    "                    mask = gaussian_filter(mask, sigma=(diagonal/10,diagonal/10,0), mode='nearest') \n",
    "                    mask = mask / 255\n",
    "                    frame_blur = gaussian_filter(frame, sigma=(diagonal/10,diagonal/10,0), mode='nearest') \n",
    "                    final_image = mask * frame + (1-mask) * frame_blur\n",
    "                    out.write(final_image.astype(np.uint8))\n",
    "                else:\n",
    "                    out.write(frame)\n",
    "        # read next frame\n",
    "        succes = video.grab()\n",
    "        frame_number += 1                \n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ae49e",
   "metadata": {},
   "source": [
    "### Example of video blurring, should take a couple seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1be294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_video_gauss_and_overlay(\"Test.avi\", \"Destination.avi\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
